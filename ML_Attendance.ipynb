{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e11d1a-74d4-4596-be92-d311643068de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Novel ML Attendance Taker\n",
    "# Andrew Doyle\n",
    "# 2/15/2025\n",
    "# Using Yolo12 from ultralytics to detect items for class attendance while allowing a margin of tolerance due to probabilities of image counts being the same.\n",
    "# Swapped to a segmented model as it appears to \n",
    "# Model Source:\n",
    "# https://docs.ultralytics.com/tasks/segment/\n",
    "#################################\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "###############\n",
    "# POTENTIAL ITEMS AND THEIR RESPECTIVE KEYS\n",
    "#names_list={0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: \n",
    "#'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', \n",
    "#26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', \n",
    "#38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', \n",
    "#52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', \n",
    "#66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "#################\n",
    "# Important Lib Versions\n",
    "# Numpy 1.26.4\n",
    "# ultralytics 8.3.78\n",
    "# python 3.12.4\n",
    "# pandas 2.2.2\n",
    "# opencv 4.11.2\n",
    "#################\n",
    "PYTHON_WD = os.getcwd()\n",
    "SIZE = [4,6] # Rows, Columns\n",
    "IMAGE_SIZE = [200,200] # Tile dimensions on collage\n",
    "ITEMS_LIST = ['dog','airplane','bus', 'stop sign','cat','mouse'] # Populate with items in image library for script \n",
    "TOL = 0.20 # Image error tolerance\n",
    "PERSON_THRESHOLD= 0.125 # Portion of image a person bounding box must occupy\n",
    "#################\n",
    "\n",
    "class ML_Attendance:\n",
    "    \n",
    "    def __init__(self, size, image_size, items_list, tol, person_threshold, model_path): # Set Parameters\n",
    "        self.size =size\n",
    "        self.image_size = image_size\n",
    "        self.items_list = items_list\n",
    "        tic = time.time()\n",
    "        os.chdir(model_path)\n",
    "        self.model = YOLO(\"yolo12x.pt\")#.to('cpu')  # pretrained YOLO model\n",
    "        toc = time.time()\n",
    "        runtime = toc-tic\n",
    "        print(f'Detector took: {runtime:.3f} to init')\n",
    "        self.tol = tol\n",
    "        self.person_threshold = person_threshold\n",
    "\n",
    "    def _create_img_array_(self,seed):\n",
    "        np.random.seed(seed)\n",
    "        self.rand_arr=np.random.randint(len(ITEMS_LIST), size=SIZE)\n",
    "        unique_items=np.unique(self.rand_arr)\n",
    "        temp_count = {u: 0 for u in unique_items}\n",
    "        for key in unique_items:\n",
    "            for item in self.rand_arr.flatten():\n",
    "                if item == key:\n",
    "                    temp_count[key] += 1\n",
    "        self.exp_item_count = {self.items_list[i]: temp_count[old_key] for i, old_key in enumerate(temp_count)}\n",
    "        self.unused_items = [item for item in self.items_list if item not in self.exp_item_count or self.exp_item_count[item] == 0]\n",
    "        self.used_items = [self.items_list[i] for i in unique_items]\n",
    "\n",
    "    def _item_stitch_(self):\n",
    "        x=0\n",
    "        stitched_list=[['' for i in range(self.size[1])] for j in range(self.size[0])]\n",
    "        for sub_list in self.rand_arr:\n",
    "            y=0\n",
    "            for item in sub_list:\n",
    "                stitched_list[x][y]=f'{self.items_list[item]}.jpg'\n",
    "                y+=1\n",
    "            x+=1\n",
    "        self.image_paths = stitched_list\n",
    "    \n",
    "    def _create_collage_(self,output_name):\n",
    "        collage = np.zeros((self.size[0]*self.image_size[1], self.size[1]*self.image_size[0],3),dtype=np.uint8)\n",
    "        for row_index in range(self.size[0]):\n",
    "            for col_index in range(self.size[1]):\n",
    "                img=cv2.imread(self.image_paths[row_index][col_index])\n",
    "                img = cv2.resize(img, self.image_size)\n",
    "                collage[row_index * self.image_size[1]:(row_index + 1) * self.image_size[1], col_index * self.image_size[0]:(col_index + 1) * self.image_size[0], :] = img\n",
    "        return collage\n",
    "\n",
    "    def _save_collage_(self,collage,output_name):\n",
    "        df = pd.DataFrame({'rand_arr':[self.rand_arr],'exp_item_count':[self.exp_item_count],'unused_items':[self.unused_items],'used_items':[self.used_items]})\n",
    "        df.to_json(f'{output_name}.json')\n",
    "        cv2.imwrite(f'{output_name}.jpg',collage)\n",
    "\n",
    "    def _detect_obj_(self):\n",
    "        self.detections = []\n",
    "        results = self.model.predict(self.img, imgsz = 1280)\n",
    "        boxes = results[0].boxes\n",
    "        t_label= boxes.cpu().numpy().cls.flatten()\n",
    "        names_list={0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "        label = [names_list[i] for i in t_label]\n",
    "        bbox = boxes.cpu().numpy().xyxy.round()\n",
    "        for i in range(boxes.shape[0]):\n",
    "            self.detections.append({'name':label[i],'box_points':bbox[i]})\n",
    "        \n",
    "    \n",
    "    def _obj_counter_(self):\n",
    "        obj_count = {u: 0 for u in self.used_items}\n",
    "        obj_count.update({'miss':0})\n",
    "        obj_count.update({'unused':0})\n",
    "        for i, item in enumerate(self.used_items):\n",
    "            for j, detection in enumerate(self.detections):\n",
    "                if detection['name'] == item:\n",
    "                    obj_count[item] += 1\n",
    "                elif (detection['name'] in self.unused_items) and detection['name'] != 'person': \n",
    "                    obj_count['unused'] += 1\n",
    "        for item2 in self.exp_item_count.keys():\n",
    "            obj_count['miss'] += np.abs(self.exp_item_count[item2]-obj_count[item2])\n",
    "        self.obj_count = obj_count\n",
    "        \n",
    "    def _evaluate_counts_(self): # Finds the difference between expected count and found\n",
    "        self.error = 0\n",
    "        max_error = math.floor(self.size[0]*self.size[1]*self.tol)\n",
    "        print(f'Max Error: {max_error}')\n",
    "        for key in self.exp_item_count.keys():\n",
    "            if self.obj_count[key] != self.exp_item_count[key]:\n",
    "                self.error += np.abs(self.obj_count[key]-self.exp_item_count[key])\n",
    "        if self.error> max_error:\n",
    "            self.suff_match = False\n",
    "        else:\n",
    "            self.suff_match = True\n",
    "            \n",
    "    def _check_person_(self):\n",
    "        self.person_flag = False\n",
    "        for detection in self.detections:\n",
    "            if detection['name'] == 'person':\n",
    "                x=detection['box_points'][2] - detection['box_points'][0]\n",
    "                y=detection['box_points'][3] - detection['box_points'][1]\n",
    "                person_area = x*y\n",
    "                if person_area >= self.area * self.person_threshold:\n",
    "                    self.person_flag = True\n",
    "                    print(f'Person found with percentage: {person_area/self.area * 100:.2f}%')\n",
    "                    return\n",
    "                else:\n",
    "                    self.person_flag = False\n",
    "                    \n",
    "    def create_code_img(self,img_lib,output_path,output_name,seed=np.random.randint(time.time())): # Executes all functions to properly create the collage\n",
    "        tic = time.time()\n",
    "        self._create_img_array_(seed)\n",
    "        self._item_stitch_()\n",
    "        current_directory = os.getcwd()\n",
    "        os.chdir(img_lib)\n",
    "        collage = self._create_collage_(output_name)\n",
    "        os.chdir(output_path)\n",
    "        self._save_collage_(collage,output_name)\n",
    "        os.chdir(current_directory)\n",
    "        toc = time.time()\n",
    "        runtime = toc-tic\n",
    "        print(f'Image Generation time : {runtime:.3f}')\n",
    "        \n",
    "    def read_data(self, output_path, filename):\n",
    "        os.chdir(output_path)\n",
    "        df = pd.read_json(filename)\n",
    "        self.rand_arr = df.rand_arr.to_list()[0]\n",
    "        self.exp_item_count = df.exp_item_count.to_dict()[0]\n",
    "        self.unused_items = df.unused_items.to_list()[0]\n",
    "        self.used_items = df.used_items.to_list()[0]\n",
    "\n",
    "    def evaluate_img(self, img): # Executes all functions to evaluate an image and compare datapoints to the source.\n",
    "        tic1 = time.time()\n",
    "        self.img= img\n",
    "        self.height, self.width, channels = cv2.imread(img).shape\n",
    "        self.area = self.height*self.width\n",
    "        tic2= time.time()\n",
    "        self._detect_obj_()\n",
    "        toc2 = time.time()\n",
    "        run_time2 = toc2-tic2\n",
    "        print(f'Yolo12x Runtime: {run_time2:.3f}')\n",
    "        self._obj_counter_()\n",
    "        self._evaluate_counts_()\n",
    "        self._check_person_()\n",
    "        toc1 = time.time()\n",
    "        run_time1 = toc1-tic1\n",
    "        print(f'Evaluation Runtime: {run_time1:.3f}')\n",
    "        # print(f'Total Error: {self.error}\\nSufficient Match?: {self.suff_match}\\n{self.person_threshold*100:.2f}% Person? {self.person_flag}\\nUnused Items in photo: {self.obj_count['unused']}')\n",
    "        if not self.person_flag or not self.suff_match:\n",
    "            print(f'Reccommending review for Image: {self.img}')\n",
    "        return self.error, self.suff_match, self.person_flag, self.suff_match and self.person_flag\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e741424b-1036-4b98-91d9-39985057b10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Jupyter\\ML_Attendance\\ml_attendance\\config.yml\n",
      "Config Not Found\n"
     ]
    }
   ],
   "source": [
    "Evaluater = None # Predefine var useful later\n",
    "\n",
    "####################################\n",
    "# CONFIG Functions\n",
    "####################################\n",
    "def load_config(config=os.path.join(PYTHON_WD,'config.yml')):\n",
    "    print(config)\n",
    "    if os.path.exists(config):\n",
    "        with open(config,'r') as f:\n",
    "            config_data = yaml.safe_load(f)\n",
    "            mod_path = config_data['mod_path']\n",
    "            out_path = config_data['out_path']\n",
    "            lib_path = config_data['lib_path']\n",
    "            input_path = config_data['input_path']\n",
    "            tol = config_data['tol']\n",
    "            person_threshold = config_data['person_threshold']\n",
    "        return mod_path,out_path,lib_path,input_path,tol,person_threshold\n",
    "    else:\n",
    "        print('Config Not Found')\n",
    "        return '','','','',0.20,0.125\n",
    "\n",
    "def save_config(mod_path,out_path,lib_path,input_path,tol,person_threshold):\n",
    "    with open(os.path.join(PYTHON_WD,'config.yml'),'w') as f:\n",
    "        config_data = {'mod_path':mod_path,'out_path':out_path,'lib_path':lib_path,'input_path':input_path,'tol':tol,'person_threshold':person_threshold}\n",
    "        yaml.dump(config_data, f)\n",
    "    return\n",
    "\n",
    "def file_sel_gui():\n",
    "    f=tk.filedialog.askdirectory()\n",
    "    return f\n",
    "\n",
    "####################################\n",
    "# GUI Button Functions\n",
    "####################################\n",
    "def validate_float_input(P):\n",
    "    # Check if the input is a valid float (allowing empty string for backspace).\n",
    "    if P == \"\" or P.replace('.', '', 1).isdigit():\n",
    "        try:\n",
    "            float(P)  # Try to convert the input to a float.\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_img_gui(img_lib,output_path,model_path):\n",
    "    Evaluater = ML_Attendance(SIZE, IMAGE_SIZE, ITEMS_LIST, TOL, PERSON_THRESHOLD,model_path)\n",
    "    sec = time.time()\n",
    "    timestamp = datetime.fromtimestamp(sec).strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    fname = tk.simpledialog.askstring('Image Dialog','Image Name: ', initialvalue=timestamp)\n",
    "    Evaluater.create_code_img(img_lib,output_path,fname)\n",
    "    \n",
    "def eval_bulk(input_path,model_path):\n",
    "    Evaluater = ML_Attendance(SIZE, IMAGE_SIZE, ITEMS_LIST, TOL, PERSON_THRESHOLD,model_path)\n",
    "\n",
    "    for filename in os.listdir(file_path):\n",
    "    # Construct the full file path\n",
    "        full_path = os.path.join(file_path, filename)\n",
    "\n",
    "        # Check if it is a file and an image (you may need to refine the extensions)\n",
    "        if os.path.isfile(full_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp','.heic','.tif','.tiff')):\n",
    "            # Process the image file\n",
    "            print(f\"Processing image: {full_path}\")\n",
    "            \n",
    "            Evaluater.evaluate_img(cv2.imread(full_path))\n",
    "            # Add your image processing logic here, e.g., opening with PIL or other libraries\n",
    "        elif os.path.isfile(full_path):\n",
    "          print(f\"Skipping non-image file: {full_path}\")\n",
    "##########################\n",
    "# GUI Stuff\n",
    "##########################\n",
    "root = tk.Tk()\n",
    "\n",
    "fpath_model = tk.StringVar()\n",
    "fpath_output = tk.StringVar()\n",
    "fpath_imglib = tk.StringVar()\n",
    "fpath_config = tk.StringVar()\n",
    "fpath_input = tk.StringVar()\n",
    "gui_tol = tk.DoubleVar()\n",
    "gui_person_threshold = tk.DoubleVar()\n",
    "\n",
    "\n",
    "temp = load_config()\n",
    "\n",
    "fpath_model.set(temp[0])\n",
    "fpath_output.set(temp[1])\n",
    "fpath_imglib.set(temp[2])\n",
    "fpath_input.set(temp[3])\n",
    "gui_tol.set(temp[4])\n",
    "gui_person_threshold.set(temp[5])\n",
    "\n",
    "del temp\n",
    "root.title('ML Attendance')\n",
    "frm = ttk.Frame(root,padding = 10)\n",
    "frm.grid()\n",
    "\n",
    "ttk.Label(frm, text='Model Path').grid(column=0,row=0)\n",
    "model_entry=tk.Entry(frm,textvariable=fpath_model,width = 50)\n",
    "model_entry.grid(column=0,row=1,columnspan=5)\n",
    "ttk.Button(frm,text='File Select',command = lambda: fpath_model.set(file_sel_gui())).grid(column=6, row=1,sticky='w')\n",
    "\n",
    "ttk.Label(frm, text='Output Path').grid(column=0,row=2)\n",
    "output_entry=tk.Entry(frm,textvariable=fpath_output,width = 50)\n",
    "output_entry.grid(column=0,row=3,columnspan=5)\n",
    "ttk.Button(frm,text='File Select',command = lambda: fpath_output.set(file_sel_gui())).grid(column=6, row=3,sticky='w')\n",
    "\n",
    "ttk.Label(frm, text='Img Lib Path').grid(column=0,row=4)\n",
    "imglib_entry=tk.Entry(frm,textvariable=fpath_imglib,width = 50)\n",
    "imglib_entry.grid(column=0,row=5,columnspan=5)\n",
    "ttk.Button(frm,text='File Select',command = lambda: fpath_imglib.set(file_sel_gui())).grid(column=6, row=5,sticky='w')\n",
    "\n",
    "ttk.Label(frm, text='Input Folder Path').grid(column=0,row=6)\n",
    "input_entry=tk.Entry(frm,textvariable=fpath_input,width = 50)\n",
    "input_entry.grid(column=0,row=7,columnspan=5)\n",
    "ttk.Button(frm,text='File Select',command = lambda: fpath_input.set(file_sel_gui())).grid(column=6, row=7,sticky='w')\n",
    "\n",
    "ttk.Label(frm,text = 'Note: Config Generates on quit into Python file\\'s Directory').grid(column=0,row=8,columnspan=5)\n",
    "\n",
    "ttk.Label(frm,text='Error Tolerance:').grid(column=0,row=9)\n",
    "tol_entry=tk.Entry(frm, validate='key', textvariable=gui_tol,validatecommand=(root.register(validate_float_input), '%P')).grid(column=1,row=9)\n",
    "ttk.Label(frm,text='Person Thresh:').grid(column=2,row=9)\n",
    "person_thresh_entry=tk.Entry(frm, validate='key', textvariable=gui_person_threshold,validatecommand=(root.register(validate_float_input), '%P')).grid(column=3,row=9)\n",
    "\n",
    "\n",
    "ttk.Button(frm,text='Generate Img',command = lambda: generate_img_gui(fpath_imglib.get(),fpath_output.get(),fpath_model.get())).grid(column=1, row=10,sticky='w')\n",
    "ttk.Button(frm,text='Evaluate',command = lambda:eval_bulk()).grid(column=2, row=10,sticky='w')\n",
    "ttk.Button(frm,text='Save & Quit',command = lambda:[save_config(fpath_model.get(),fpath_output.get(),fpath_imglib.get(),fpath_input.get(),gui_tol.get(),gui_person_threshold.get()),root.destroy()]).grid(column=3, row=10,sticky='w')\n",
    "root.mainloop()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
